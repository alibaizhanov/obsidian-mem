"""
Embedder ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö embeddings.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç sentence-transformers —Å –º–æ–¥–µ–ª—å—é all-MiniLM-L6-v2:
- 80MB —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
- 384-–º–µ—Ä–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞
- –ù–∞ Mac M1 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Metal GPU –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- –ü–æ–ª–Ω–æ—Å—Ç—å—é –ª–æ–∫–∞–ª—å–Ω–æ, –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –≤ –æ–±–ª–∞–∫–æ
"""

from sentence_transformers import SentenceTransformer
from typing import Optional
import numpy as np


class Embedder:
    """–õ–æ–∫–∞–ª—å–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä embeddings"""

    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        self.model_name = model_name
        self._model: Optional[SentenceTransformer] = None

    @property
    def model(self) -> SentenceTransformer:
        """Lazy loading ‚Äî –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏"""
        if self._model is None:
            print(f"üß† –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å {self.model_name}...")
            self._model = SentenceTransformer(self.model_name)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({self.dimensions}D)")
        return self._model

    @property
    def dimensions(self) -> int:
        return self.model.get_sentence_embedding_dimension()

    def embed(self, text: str) -> np.ndarray:
        """Embed –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ ‚Üí –≤–µ–∫—Ç–æ—Ä"""
        return self.model.encode(text, normalize_embeddings=True)

    def embed_batch(self, texts: list[str], batch_size: int = 32) -> np.ndarray:
        """Embed –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ ‚Üí –º–∞—Ç—Ä–∏—Ü–∞ –≤–µ–∫—Ç–æ—Ä–æ–≤"""
        return self.model.encode(
            texts,
            batch_size=batch_size,
            normalize_embeddings=True,
            show_progress_bar=len(texts) > 50,
        )

    def similarity(self, vec_a: np.ndarray, vec_b: np.ndarray) -> float:
        """Cosine similarity –º–µ–∂–¥—É –¥–≤—É–º—è –≤–µ–∫—Ç–æ—Ä–∞–º–∏"""
        return float(np.dot(vec_a, vec_b))

    def search(self, query_vec: np.ndarray, corpus_vecs: np.ndarray, top_k: int = 5) -> list[tuple[int, float]]:
        """
        –ü–æ–∏—Å–∫ top-K –±–ª–∏–∂–∞–π—à–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç [(index, score), ...]
        """
        scores = np.dot(corpus_vecs, query_vec)
        top_indices = np.argsort(scores)[::-1][:top_k]
        return [(int(idx), float(scores[idx])) for idx in top_indices]


if __name__ == "__main__":
    embedder = Embedder()

    # –¢–µ—Å—Ç
    texts = [
        "PostgreSQL connection pool exhaustion",
        "–ü—Ä–æ–±–ª–µ–º—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–µ",
        "React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞",
        "Kafka consumer lag issues",
    ]

    vectors = embedder.embed_batch(texts)
    print(f"\nüìê Vectors shape: {vectors.shape}")

    query = embedder.embed("–ø—Ä–æ–±–ª–µ–º–∞ —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    results = embedder.search(query, vectors, top_k=3)

    print(f"\nüîç Query: '–ø—Ä–æ–±–ª–µ–º–∞ —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö'")
    for idx, score in results:
        print(f"   {score:.3f}  {texts[idx]}")
