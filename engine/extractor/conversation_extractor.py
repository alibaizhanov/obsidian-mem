"""
Conversation Extractor v2 ‚Äî –∏–∑–≤–ª–µ–∫–∞–µ—Ç RICH –∑–Ω–∞–Ω–∏—è –∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.

–ò–∑–≤–ª–µ–∫–∞–µ—Ç:
1. Entities (person, project, technology, company, concept)
2. Facts ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
3. Relations ‚Äî —Å–≤—è–∑–∏ –º–µ–∂–¥—É entities
4. Knowledge ‚Äî —Ä–µ—à–µ–Ω–∏—è, —Ñ–æ—Ä–º—É–ª—ã, —Ä–µ—Ü–µ–ø—Ç—ã, –∫–æ–Ω—Ñ–∏–≥–∏, –∫–æ–º–∞–Ω–¥—ã (—Å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏)

Knowledge ‚Äî —ç—Ç–æ killer feature. LLM —Å–∞–º –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∑–Ω–∞–Ω–∏—è:
  [solution] ‚Äî —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã (–∫–æ–¥, –∫–æ–Ω—Ñ–∏–≥)
  [formula] ‚Äî —Ñ–æ—Ä–º—É–ª–∞, —É—Ä–∞–≤–Ω–µ–Ω–∏–µ
  [treatment] ‚Äî –ª–µ—á–µ–Ω–∏–µ, –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ
  [experiment] ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
  [recipe] ‚Äî —Ä–µ—Ü–µ–ø—Ç (–∫—É–ª–∏–Ω–∞—Ä–∏—è, –ø—Ä–æ—Ü–µ—Å—Å)
  [decision] ‚Äî –ø—Ä–∏–Ω—è—Ç–æ–µ —Ä–µ—à–µ–Ω–∏–µ
  [command] ‚Äî –ø–æ–ª–µ–∑–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ / –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
  [reference] ‚Äî —Å—Å—ã–ª–∫–∞, –∏—Å—Ç–æ—á–Ω–∏–∫
  [insight] ‚Äî –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ, –∏–Ω—Å–∞–π—Ç
  [example] ‚Äî –ø—Ä–∏–º–µ—Ä, –∫–µ–π—Å
  ... –ª—é–±–æ–π –¥—Ä—É–≥–æ–π —Ç–∏–ø –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ —Å–º—ã—Å–ª—É
"""

import sys
import json
from dataclasses import dataclass, field
from typing import Optional

from engine.extractor.llm_client import LLMClient


EXTRACTION_PROMPT = """You are a precision knowledge extraction system. Extract IMPORTANT, LASTING personal knowledge from the USER's messages.

Return ONLY valid JSON without markdown. Be VERY selective ‚Äî quality over quantity.

WHO TO EXTRACT ABOUT:
- Extract knowledge revealed by the USER about themselves, their projects, their life
- DO NOT extract general knowledge the assistant explained (e.g. "nginx config is at /etc/nginx" ‚Äî unless user confirms they used it)
- If assistant suggests something and user says "yes, I did that" or "that worked" ‚Äî extract the user's action/result
- Focus on: user's identity, skills, preferences, projects, decisions, workflows, relationships

ENTITY RULES:
- ONLY named, specific entities with 2+ extractable facts
- If something is mentioned once in passing ‚Äî make it a fact on the parent entity, NOT a separate entity
  GOOD: Entity "Mengram" ‚Üí fact: "uses Redis as cache"
  BAD: Entity "Redis" ‚Üí fact: "used as cache" (only 1 fact, make it a fact on the project instead)
- entity_type: person, project, technology, company, concept
- If user says "I"/"me"/"my" ‚Äî resolve to their name if known, otherwise "User"
{existing_context}
ENTITY NAMING:
- EXACT casing from context: "Mengram" not "MENGRAM", "PostgreSQL" not "postgresql"
- FULL official name: "Ali Baizhanov" not "Ali", "Uzum Bank" not "uzum"
- If entity already exists above ‚Äî use EXACT SAME NAME (do not create duplicates)

FACT RULES:
- Normalized format: subject + verb + object, present tense, under 10 words
  GOOD: "uses Python", "deployed on Railway", "prefers dark mode"
  BAD: "he has been using Python for a while now", "is currently in the process of deploying"
- ONLY facts that DIRECTLY describe the entity they're assigned to
- Keep project facts on projects, personal facts on the person ‚Äî don't mix
- DO NOT extract: temporary actions ("asked about X"), session events ("sent a message"), assistant's explanations

FACT DEDUP ‚Äî check existing facts above. Do NOT re-extract facts that already exist (even if worded slightly differently).
If user says "I use Python" and existing context already has "uses Python" ‚Üí skip it.
If user says "I switched from React to Svelte" and existing has "uses React" ‚Üí extract "switched to Svelte" (this is NEW info).

Response format (strict JSON, no ```):
{{
  "entities": [
    {{
      "name": "Entity Name",
      "type": "person|project|technology|company|concept",
      "facts": ["fact 1", "fact 2"]
    }}
  ],
  "relations": [
    {{
      "from": "Entity 1",
      "to": "Entity 2",
      "type": "works_at|uses|member_of|related_to|depends_on|created_by",
      "description": "short description"
    }}
  ],
  "knowledge": [
    {{
      "entity": "Entity this knowledge belongs to",
      "type": "solution|formula|command|insight|decision|recipe|reference",
      "title": "Short descriptive title",
      "content": "Detailed explanation",
      "artifact": "code/config/formula/command (optional, null if none)"
    }}
  ]
}}

EXAMPLE:
Input conversation:
  User: "–Ø –≤—á–µ—Ä–∞ –∑–∞–¥–µ–ø–ª–æ–∏–ª mengram –Ω–∞ Railway, –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç. –ü—Ä–∏—à–ª–æ—Å—å –ø–æ–≤–æ–∑–∏—Ç—å—Å—è —Å pgvector"
  Assistant: "–û—Ç–ª–∏—á–Ω–æ! –ö–∞–∫–∞—è –≤–µ—Ä—Å–∏—è PostgreSQL?"
  User: "15-—è, –Ω–∞ Supabase —Ö–æ—Å—Ç–∏—Ç—Å—è"

Output:
{{
  "entities": [
    {{"name": "Mengram", "type": "project", "facts": ["deployed on Railway", "uses pgvector extension"]}},
    {{"name": "Supabase", "type": "technology", "facts": ["hosts PostgreSQL 15 for Mengram"]}}
  ],
  "relations": [
    {{"from": "Mengram", "to": "Railway", "type": "depends_on", "description": "deployed on"}},
    {{"from": "Mengram", "to": "Supabase", "type": "depends_on", "description": "database hosting"}}
  ],
  "knowledge": []
}}

CONVERSATION:
{conversation}

Extract knowledge (return ONLY JSON):"""


EXISTING_CONTEXT_BLOCK = """
EXISTING ENTITIES FOR THIS USER (use same names, avoid duplicate facts):
{context}
"""


@dataclass
class ExtractedEntity:
    """–ò–∑–≤–ª–µ—á—ë–Ω–Ω–∞—è —Å—É—â–Ω–æ—Å—Ç—å"""
    name: str
    entity_type: str  # person, project, technology, company, concept
    facts: list[str] = field(default_factory=list)

    def __repr__(self):
        return f"Entity({self.entity_type}: {self.name}, facts={len(self.facts)})"


@dataclass
class ExtractedRelation:
    """–ò–∑–≤–ª–µ—á—ë–Ω–Ω–∞—è —Å–≤—è–∑—å"""
    from_entity: str
    to_entity: str
    relation_type: str
    description: str = ""

    def __repr__(self):
        return f"Relation({self.from_entity} --{self.relation_type}--> {self.to_entity})"


@dataclass
class ExtractedKnowledge:
    """–ò–∑–≤–ª–µ—á—ë–Ω–Ω–æ–µ –∑–Ω–∞–Ω–∏–µ ‚Äî solution, formula, command, etc."""
    entity: str           # –∫ –∫–∞–∫–æ–π entity –æ—Ç–Ω–æ—Å–∏—Ç—Å—è
    knowledge_type: str   # solution, formula, treatment, command, insight, ...
    title: str            # –∫—Ä–∞—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    content: str          # –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
    artifact: Optional[str] = None  # –∫–æ–¥, –∫–æ–Ω—Ñ–∏–≥, —Ñ–æ—Ä–º—É–ª–∞, –∫–æ–º–∞–Ω–¥–∞

    def __repr__(self):
        has_artifact = "üìé" if self.artifact else ""
        return f"Knowledge([{self.knowledge_type}] {self.title} ‚Üí {self.entity} {has_artifact})"


@dataclass
class ExtractionResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞"""
    entities: list[ExtractedEntity] = field(default_factory=list)
    relations: list[ExtractedRelation] = field(default_factory=list)
    knowledge: list[ExtractedKnowledge] = field(default_factory=list)
    raw_response: str = ""

    def __repr__(self):
        return (
            f"ExtractionResult(entities={len(self.entities)}, "
            f"relations={len(self.relations)}, "
            f"knowledge={len(self.knowledge)})"
        )


class ConversationExtractor:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤"""

    def __init__(self, llm_client: LLMClient):
        self.llm = llm_client

    def extract(self, conversation: list[dict], existing_context: str = "") -> ExtractionResult:
        conv_text = self._format_conversation(conversation)

        # Build context block
        if existing_context:
            context_block = EXISTING_CONTEXT_BLOCK.format(context=existing_context)
        else:
            context_block = ""

        prompt = EXTRACTION_PROMPT.format(
            conversation=conv_text,
            existing_context=context_block
        )
        raw_response = self.llm.complete(prompt)
        return self._parse_response(raw_response)

    def extract_from_text(self, text: str) -> ExtractionResult:
        conversation = [{"role": "user", "content": text}]
        return self.extract(conversation)

    def _format_conversation(self, conversation: list[dict]) -> str:
        lines = []
        for msg in conversation:
            role = "User" if msg["role"] == "user" else "Assistant"
            lines.append(f"{role}: {msg['content']}")
        return "\n\n".join(lines)

    def _parse_response(self, raw: str) -> ExtractionResult:
        result = ExtractionResult(raw_response=raw)

        # Clean markdown
        clean = raw.strip()
        if clean.startswith("```"):
            lines = clean.split("\n")
            clean = "\n".join(lines[1:-1] if lines[-1].strip() == "```" else lines[1:])

        try:
            data = json.loads(clean)
        except json.JSONDecodeError:
            start = raw.find("{")
            end = raw.rfind("}") + 1
            if start >= 0 and end > start:
                try:
                    data = json.loads(raw[start:end])
                except json.JSONDecodeError:
                    print(f"‚ö†Ô∏è  Failed to parse JSON from LLM", file=sys.stderr)
                    return result
            else:
                print(f"‚ö†Ô∏è  LLM returned no JSON", file=sys.stderr)
                return result

        # Entities
        for e in data.get("entities", []):
            result.entities.append(ExtractedEntity(
                name=e.get("name", "Unknown"),
                entity_type=e.get("type", "concept"),
                facts=e.get("facts", []),
            ))

        # Relations
        for r in data.get("relations", []):
            result.relations.append(ExtractedRelation(
                from_entity=r.get("from", ""),
                to_entity=r.get("to", ""),
                relation_type=r.get("type", "related_to"),
                description=r.get("description", ""),
            ))

        # Knowledge (NEW)
        for k in data.get("knowledge", []):
            result.knowledge.append(ExtractedKnowledge(
                entity=k.get("entity", ""),
                knowledge_type=k.get("type", "insight"),
                title=k.get("title", ""),
                content=k.get("content", ""),
                artifact=k.get("artifact"),
            ))

        return result


# --- Mock for testing ---

class MockLLMClient(LLMClient):
    """Mock LLM for testing without API"""

    def complete(self, prompt: str, system: str = "") -> str:
        return json.dumps({
            "entities": [
                {
                    "name": "User",
                    "type": "person",
                    "facts": [
                        "–†–∞–±–æ—Ç–∞–µ—Ç backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–º",
                        "–†–∞–±–æ—Ç–∞–µ—Ç –≤ Uzum Bank",
                        "–û—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–µ–∫: Java, Spring Boot"
                    ]
                },
                {
                    "name": "Uzum Bank",
                    "type": "company",
                    "facts": ["–ë–∞–Ω–∫ –≤ –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω–µ", "–ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞"]
                },
                {
                    "name": "–ü—Ä–æ–µ–∫—Ç Alpha",
                    "type": "project",
                    "facts": ["Backend —Å–µ—Ä–≤–∏—Å –¥–ª—è –ø–ª–∞—Ç–µ–∂–µ–π", "–ü—Ä–æ–±–ª–µ–º–∞ —Å connection pool"]
                },
                {
                    "name": "PostgreSQL",
                    "type": "technology",
                    "facts": ["–û—Å–Ω–æ–≤–Ω–∞—è –ë–î", "–í–µ—Ä—Å–∏—è 15"]
                },
                {
                    "name": "Spring Boot",
                    "type": "technology",
                    "facts": ["–û—Å–Ω–æ–≤–Ω–æ–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤"]
                }
            ],
            "relations": [
                {"from": "User", "to": "Uzum Bank", "type": "works_at", "description": "Backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫"},
                {"from": "User", "to": "–ü—Ä–æ–µ–∫—Ç Alpha", "type": "member_of", "description": "–†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞–¥ –ø—Ä–æ–µ–∫—Ç–æ–º"},
                {"from": "–ü—Ä–æ–µ–∫—Ç Alpha", "to": "PostgreSQL", "type": "uses", "description": "–û—Å–Ω–æ–≤–Ω–∞—è –ë–î"},
                {"from": "–ü—Ä–æ–µ–∫—Ç Alpha", "to": "Spring Boot", "type": "uses", "description": "Backend —Ñ—Ä–µ–π–º–≤–æ—Ä–∫"},
                {"from": "Uzum Bank", "to": "–ü—Ä–æ–µ–∫—Ç Alpha", "type": "related_to", "description": "–ü—Ä–æ–µ–∫—Ç –±–∞–Ω–∫–∞"}
            ],
            "knowledge": [
                {
                    "entity": "PostgreSQL",
                    "type": "solution",
                    "title": "Connection pool exhaustion fix",
                    "content": "OOM –ø—Ä–∏ 200+ WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è—Ö. –ö–∞–∂–¥—ã–π WS –¥–µ—Ä–∂–∞–ª –æ—Ç–¥–µ–ª—å–Ω—ã–π connection. –†–µ—à–µ–Ω–∏–µ: Redis –∫–µ—à –¥–ª—è UserService –∏ BlockedAccountService.",
                    "artifact": "spring.datasource.hikari.maximum-pool-size: 20\nspring.datasource.hikari.idle-timeout: 30000\nspring.datasource.hikari.connection-timeout: 5000"
                },
                {
                    "entity": "PostgreSQL",
                    "type": "command",
                    "title": "Check active connections",
                    "content": "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π PostgreSQL",
                    "artifact": "SELECT count(*), state FROM pg_stat_activity GROUP BY state;"
                }
            ]
        }, ensure_ascii=False)
