"""
Conversation Extractor ‚Äî –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞–Ω–∏—è –∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ —Å AI.

–ë–µ—Ä—ë—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä (user + assistant —Å–æ–æ–±—â–µ–Ω–∏—è) –∏ —Å –ø–æ–º–æ—â—å—é LLM:
1. –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—É—â–Ω–æ—Å—Ç–∏ (–ª—é–¥–∏, –ø—Ä–æ–µ–∫—Ç—ã, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∫–æ–º–ø–∞–Ω–∏–∏)
2. –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∞–∫—Ç—ã –æ –∫–∞–∂–¥–æ–π —Å—É—â–Ω–æ—Å—Ç–∏
3. –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Å—É—â–Ω–æ—Å—Ç—è–º–∏
4. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ vault
"""

import json
from dataclasses import dataclass, field
from typing import Optional

from engine.extractor.llm_client import LLMClient


EXTRACTION_PROMPT = """–¢—ã ‚Äî —Å–∏—Å—Ç–µ–º–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–∞–∑–≥–æ–≤–æ—Ä –º–µ–∂–¥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º.

–ò–∑–≤–ª–µ–∫–∏ –í–°–ï —Å—É—â–Ω–æ—Å—Ç–∏, —Ñ–∞–∫—Ç—ã –∏ —Å–≤—è–∑–∏. –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ markdown.

–ü—Ä–∞–≤–∏–ª–∞:
- entity_type: person, project, technology, company, concept
- –§–∞–∫—Ç—ã ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–µ, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
- –°–≤—è–∑–∏ ‚Äî –∫–∞–∫ —Å—É—â–Ω–æ—Å—Ç–∏ —Å–≤—è–∑–∞–Ω—ã –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º
- –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç "—è" ‚Äî —ç—Ç–æ —Å—É—â–Ω–æ—Å—Ç—å —Å –∏–º–µ–Ω–µ–º "User" (type: person)
- –ò–∑–≤–ª–µ–∫–∞–π –¥–∞–∂–µ –Ω–µ—è–≤–Ω—ã–µ —Ñ–∞–∫—Ç—ã (–µ—Å–ª–∏ –≥–æ–≤–æ—Ä–∏—Ç "–º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º Kafka" ‚Äî –∑–Ω–∞—á–∏—Ç –µ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç –≥–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Kafka)

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (—Å—Ç—Ä–æ–≥–æ JSON, –±–µ–∑ ```):
{{
  "entities": [
    {{
      "name": "–ò–º—è —Å—É—â–Ω–æ—Å—Ç–∏",
      "type": "person|project|technology|company|concept",
      "facts": [
        "—Ñ–∞–∫—Ç 1 –æ–± —ç—Ç–æ–π —Å—É—â–Ω–æ—Å—Ç–∏",
        "—Ñ–∞–∫—Ç 2 –æ–± —ç—Ç–æ–π —Å—É—â–Ω–æ—Å—Ç–∏"
      ]
    }}
  ],
  "relations": [
    {{
      "from": "–ò–º—è —Å—É—â–Ω–æ—Å—Ç–∏ 1",
      "to": "–ò–º—è —Å—É—â–Ω–æ—Å—Ç–∏ 2",
      "type": "works_at|uses|member_of|related_to|depends_on|created_by",
      "description": "–æ–ø–∏—Å–∞–Ω–∏–µ —Å–≤—è–∑–∏"
    }}
  ]
}}

–†–ê–ó–ì–û–í–û–†:
{conversation}

–ò–∑–≤–ª–µ–∫–∏ –∑–Ω–∞–Ω–∏—è (–≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON):"""


@dataclass
class ExtractedEntity:
    """–ò–∑–≤–ª–µ—á—ë–Ω–Ω–∞—è —Å—É—â–Ω–æ—Å—Ç—å"""
    name: str
    entity_type: str  # person, project, technology, company, concept
    facts: list[str] = field(default_factory=list)

    def __repr__(self):
        return f"Entity({self.entity_type}: {self.name}, facts={len(self.facts)})"


@dataclass
class ExtractedRelation:
    """–ò–∑–≤–ª–µ—á—ë–Ω–Ω–∞—è —Å–≤—è–∑—å"""
    from_entity: str
    to_entity: str
    relation_type: str
    description: str = ""

    def __repr__(self):
        return f"Relation({self.from_entity} --{self.relation_type}--> {self.to_entity})"


@dataclass
class ExtractionResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞"""
    entities: list[ExtractedEntity] = field(default_factory=list)
    relations: list[ExtractedRelation] = field(default_factory=list)
    raw_response: str = ""

    def __repr__(self):
        return f"ExtractionResult(entities={len(self.entities)}, relations={len(self.relations)})"


class ConversationExtractor:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤"""

    def __init__(self, llm_client: LLMClient):
        self.llm = llm_client

    def extract(self, conversation: list[dict]) -> ExtractionResult:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞–Ω–∏—è –∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.

        Args:
            conversation: —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π [{"role": "user"|"assistant", "content": "..."}]

        Returns:
            ExtractionResult —Å entities –∏ relations
        """
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–∞–∑–≥–æ–≤–æ—Ä
        conv_text = self._format_conversation(conversation)

        # –í—ã–∑—ã–≤–∞–µ–º LLM
        prompt = EXTRACTION_PROMPT.format(conversation=conv_text)
        raw_response = self.llm.complete(prompt)

        # –ü–∞—Ä—Å–∏–º JSON
        return self._parse_response(raw_response)

    def extract_from_text(self, text: str) -> ExtractionResult:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞–Ω–∏—è –∏–∑ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        conversation = [{"role": "user", "content": text}]
        return self.extract(conversation)

    def _format_conversation(self, conversation: list[dict]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä –≤ —Ç–µ–∫—Å—Ç"""
        lines = []
        for msg in conversation:
            role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg["role"] == "user" else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
            lines.append(f"{role}: {msg['content']}")
        return "\n\n".join(lines)

    def _parse_response(self, raw: str) -> ExtractionResult:
        """–ü–∞—Ä—Å–∏—Ç JSON –æ—Ç–≤–µ—Ç –æ—Ç LLM"""
        result = ExtractionResult(raw_response=raw)

        # –ß–∏—Å—Ç–∏–º –æ—Ç–≤–µ—Ç –æ—Ç markdown
        clean = raw.strip()
        if clean.startswith("```"):
            # –£–±–∏—Ä–∞–µ–º ```json –∏ ```
            lines = clean.split("\n")
            clean = "\n".join(lines[1:-1] if lines[-1].strip() == "```" else lines[1:])

        try:
            data = json.loads(clean)
        except json.JSONDecodeError:
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ JSON –≤ —Ç–µ–∫—Å—Ç–µ
            start = raw.find("{")
            end = raw.rfind("}") + 1
            if start >= 0 and end > start:
                try:
                    data = json.loads(raw[start:end])
                except json.JSONDecodeError:
                    print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç LLM")
                    return result
            else:
                print(f"‚ö†Ô∏è  LLM –Ω–µ –≤–µ—Ä–Ω—É–ª JSON")
                return result

        # –ò–∑–≤–ª–µ–∫–∞–µ–º entities
        for e in data.get("entities", []):
            result.entities.append(ExtractedEntity(
                name=e.get("name", "Unknown"),
                entity_type=e.get("type", "concept"),
                facts=e.get("facts", []),
            ))

        # –ò–∑–≤–ª–µ–∫–∞–µ–º relations
        for r in data.get("relations", []):
            result.relations.append(ExtractedRelation(
                from_entity=r.get("from", ""),
                to_entity=r.get("to", ""),
                relation_type=r.get("type", "related_to"),
                description=r.get("description", ""),
            ))

        return result


# --- –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ LLM API ---

class MockLLMClient(LLMClient):
    """–ú–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ LLM"""

    def complete(self, prompt: str, system: str = "") -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∏–º–µ—Ä –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        return json.dumps({
            "entities": [
                {
                    "name": "User",
                    "type": "person",
                    "facts": [
                        "–†–∞–±–æ—Ç–∞–µ—Ç backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–º",
                        "–†–∞–±–æ—Ç–∞–µ—Ç –≤ Uzum Bank",
                        "–û—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–µ–∫: Java, Spring Boot"
                    ]
                },
                {
                    "name": "Uzum Bank",
                    "type": "company",
                    "facts": ["–ë–∞–Ω–∫ –≤ –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω–µ", "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É"]
                },
                {
                    "name": "–ü—Ä–æ–µ–∫—Ç Alpha",
                    "type": "project",
                    "facts": ["Backend —Å–µ—Ä–≤–∏—Å –¥–ª—è –ø–ª–∞—Ç–µ–∂–µ–π", "–ü—Ä–æ–±–ª–µ–º–∞ —Å connection pool"]
                },
                {
                    "name": "PostgreSQL",
                    "type": "technology",
                    "facts": ["–û—Å–Ω–æ–≤–Ω–∞—è –ë–î", "–í–µ—Ä—Å–∏—è 15", "–ü—Ä–æ–±–ª–µ–º–∞ —Å connection pool exhaustion"]
                },
                {
                    "name": "Spring Boot",
                    "type": "technology",
                    "facts": ["–û—Å–Ω–æ–≤–Ω–æ–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤"]
                }
            ],
            "relations": [
                {"from": "User", "to": "Uzum Bank", "type": "works_at", "description": "Backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫"},
                {"from": "User", "to": "–ü—Ä–æ–µ–∫—Ç Alpha", "type": "member_of", "description": "–†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞–¥ –ø—Ä–æ–µ–∫—Ç–æ–º"},
                {"from": "–ü—Ä–æ–µ–∫—Ç Alpha", "to": "PostgreSQL", "type": "uses", "description": "–û—Å–Ω–æ–≤–Ω–∞—è –ë–î"},
                {"from": "–ü—Ä–æ–µ–∫—Ç Alpha", "to": "Spring Boot", "type": "uses", "description": "Backend —Ñ—Ä–µ–π–º–≤–æ—Ä–∫"},
                {"from": "Uzum Bank", "to": "–ü—Ä–æ–µ–∫—Ç Alpha", "type": "related_to", "description": "–ü—Ä–æ–µ–∫—Ç –±–∞–Ω–∫–∞"}
            ]
        }, ensure_ascii=False)


if __name__ == "__main__":
    # –¢–µ—Å—Ç —Å –º–æ–∫-–∫–ª–∏–µ–Ω—Ç–æ–º (–±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ API)
    print("üß™ –¢–µ—Å—Ç Conversation Extractor (mock LLM)\n")

    extractor = ConversationExtractor(MockLLMClient())

    conversation = [
        {"role": "user", "content": "–Ø —Ä–∞–±–æ—Ç–∞—é –≤ Uzum Bank, backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫. –î–µ–ª–∞—é –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã –Ω–∞ Spring Boot."},
        {"role": "assistant", "content": "–û—Ç–ª–∏—á–Ω–æ! –ö–∞–∫–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ?"},
        {"role": "user", "content": "PostgreSQL 15 –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–∞—è –ë–î. –°–µ–π—á–∞—Å –ø—Ä–æ–±–ª–µ–º–∞ —Å connection pool –≤ –ü—Ä–æ–µ–∫—Ç Alpha."},
    ]

    result = extractor.extract(conversation)
    print(f"üìä {result}\n")

    print("Entities:")
    for e in result.entities:
        print(f"  {e}")
        for fact in e.facts:
            print(f"    ‚Ä¢ {fact}")

    print(f"\nRelations:")
    for r in result.relations:
        print(f"  {r}")
