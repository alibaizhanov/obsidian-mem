"""
Vault Manager ‚Äî —Å–æ–∑–¥–∞—ë—Ç –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç .md —Ñ–∞–π–ª—ã –≤ Obsidian vault.

–ë–µ—Ä—ë—Ç ExtractionResult (entities + relations) –∏:
1. –°–æ–∑–¥–∞—ë—Ç .md —Ñ–∞–π–ª –¥–ª—è –∫–∞–∂–¥–æ–π –Ω–æ–≤–æ–π entity
2. –û–±–Ω–æ–≤–ª—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã –Ω–æ–≤—ã–º–∏ —Ñ–∞–∫—Ç–∞–º–∏
3. –î–æ–±–∞–≤–ª—è–µ—Ç [[wikilinks]] –¥–ª—è —Å–≤—è–∑–µ–π
4. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç YAML frontmatter
"""

import re
from pathlib import Path
from datetime import datetime
from typing import Optional

import yaml

from engine.extractor.conversation_extractor import (
    ExtractionResult,
    ExtractedEntity,
    ExtractedRelation,
)


class VaultManager:
    """–£–ø—Ä–∞–≤–ª—è–µ—Ç Obsidian vault ‚Äî —Å–æ–∑–¥–∞—ë—Ç/–æ–±–Ω–æ–≤–ª—è–µ—Ç .md —Ñ–∞–π–ª—ã"""

    def __init__(self, vault_path: str):
        self.vault_path = Path(vault_path)
        self.vault_path.mkdir(parents=True, exist_ok=True)
        print(f"üìÅ Vault: {self.vault_path.absolute()}")

    def process_extraction(self, extraction: ExtractionResult) -> dict:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è.
        –°–æ–∑–¥–∞—ë—Ç/–æ–±–Ω–æ–≤–ª—è–µ—Ç —Ñ–∞–π–ª—ã –≤ vault.

        Returns:
            {"created": [...], "updated": [...]}
        """
        stats = {"created": [], "updated": []}

        # 1. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é entity
        for entity in extraction.entities:
            file_path = self._entity_file_path(entity.name)

            # –ù–∞—Ö–æ–¥–∏–º —Å–≤—è–∑–∏ –¥–ª—è —ç—Ç–æ–π entity
            entity_relations = [
                r for r in extraction.relations
                if r.from_entity == entity.name or r.to_entity == entity.name
            ]

            if file_path.exists():
                self._update_note(file_path, entity, entity_relations)
                stats["updated"].append(entity.name)
            else:
                self._create_note(file_path, entity, entity_relations)
                stats["created"].append(entity.name)

        # 2. –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª—ã –¥–ª—è entities —É–ø–æ–º—è–Ω—É—Ç—ã—Ö —Ç–æ–ª—å–∫–æ –≤ relations
        all_entity_names = {e.name for e in extraction.entities}
        for rel in extraction.relations:
            for name in (rel.from_entity, rel.to_entity):
                if name not in all_entity_names:
                    file_path = self._entity_file_path(name)
                    if not file_path.exists():
                        stub = ExtractedEntity(name=name, entity_type="concept", facts=[])
                        self._create_note(file_path, stub, [])
                        stats["created"].append(name)
                        all_entity_names.add(name)

        return stats

    def _create_note(self, file_path: Path, entity: ExtractedEntity,
                     relations: list[ExtractedRelation]):
        """–°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π .md —Ñ–∞–π–ª"""
        now = datetime.now().strftime("%Y-%m-%d %H:%M")

        # Frontmatter
        frontmatter = {
            "type": entity.entity_type,
            "created": now,
            "updated": now,
            "tags": [entity.entity_type],
        }

        # –ö–æ–Ω—Ç–µ–Ω—Ç
        lines = []
        lines.append(f"# {entity.name}\n")

        # –§–∞–∫—Ç—ã
        if entity.facts:
            lines.append("## –§–∞–∫—Ç—ã\n")
            for fact in entity.facts:
                # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥—Ä—É–≥–∏—Ö entities –≤ [[links]]
                linked_fact = self._add_wikilinks(fact, entity.name)
                lines.append(f"- {linked_fact}")
            lines.append("")

        # –°–≤—è–∑–∏
        if relations:
            lines.append("## –°–≤—è–∑–∏\n")
            for rel in relations:
                other = rel.to_entity if rel.from_entity == entity.name else rel.from_entity
                direction = "‚Üí" if rel.from_entity == entity.name else "‚Üê"
                desc = f": {rel.description}" if rel.description else ""
                lines.append(f"- {direction} **{rel.relation_type}** [[{other}]]{desc}")
            lines.append("")

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª
        content = self._format_with_frontmatter(frontmatter, "\n".join(lines))
        file_path.write_text(content, encoding="utf-8")

    def _update_note(self, file_path: Path, entity: ExtractedEntity,
                     relations: list[ExtractedRelation]):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π .md —Ñ–∞–π–ª ‚Äî –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã"""
        content = file_path.read_text(encoding="utf-8")
        now = datetime.now().strftime("%Y-%m-%d %H:%M")

        # –ü–∞—Ä—Å–∏–º frontmatter
        frontmatter, body = self._parse_frontmatter(content)
        frontmatter["updated"] = now

        # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–∫—Ç—ã
        existing_facts = self._extract_existing_facts(body)

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã (—Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ)
        new_facts = []
        for fact in entity.facts:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–∫—Ç –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç (–Ω–µ—á—ë—Ç–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ)
            if not self._fact_exists(fact, existing_facts):
                new_facts.append(fact)

        if not new_facts and not relations:
            return  # –ù–µ—á–µ–≥–æ –æ–±–Ω–æ–≤–ª—è—Ç—å

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã –≤ —Å–µ–∫—Ü–∏—é "–§–∞–∫—Ç—ã"
        if new_facts:
            facts_section = "\n## –û–±–Ω–æ–≤–ª–µ–Ω–∏—è\n\n"
            facts_section += f"*{now}*\n\n"
            for fact in new_facts:
                linked_fact = self._add_wikilinks(fact, entity.name)
                facts_section += f"- {linked_fact}\n"
            body = body.rstrip() + "\n" + facts_section

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å–≤—è–∑–∏
        new_relations = []
        existing_links = set(re.findall(r"\[\[([^\]]+)\]\]", body))
        for rel in relations:
            other = rel.to_entity if rel.from_entity == entity.name else rel.from_entity
            if other not in existing_links:
                new_relations.append(rel)

        if new_relations:
            rel_section = "\n### –ù–æ–≤—ã–µ —Å–≤—è–∑–∏\n\n"
            for rel in new_relations:
                other = rel.to_entity if rel.from_entity == entity.name else rel.from_entity
                direction = "‚Üí" if rel.from_entity == entity.name else "‚Üê"
                desc = f": {rel.description}" if rel.description else ""
                rel_section += f"- {direction} **{rel.relation_type}** [[{other}]]{desc}\n"
            body = body.rstrip() + "\n" + rel_section

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π —Ñ–∞–π–ª
        content = self._format_with_frontmatter(frontmatter, body)
        file_path.write_text(content, encoding="utf-8")

    def _add_wikilinks(self, text: str, current_entity: str) -> str:
        """
        –ù–∞—Ö–æ–¥–∏—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è entities –≤ —Ç–µ–∫—Å—Ç–µ –∏ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç –≤ [[wikilinks]].
        –ò—â–µ—Ç –ø–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ñ–∞–π–ª–∞–º –≤ vault.
        """
        existing_notes = {
            p.stem for p in self.vault_path.glob("*.md")
        }

        for note_name in existing_notes:
            if note_name == current_entity:
                continue
            # Case-insensitive –∑–∞–º–µ–Ω–∞, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–≥–∏—Å—Ç—Ä
            pattern = re.compile(re.escape(note_name), re.IGNORECASE)
            # –ù–µ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –µ—Å–ª–∏ —É–∂–µ –≤ [[ ]]
            if f"[[{note_name}]]" not in text:
                text = pattern.sub(f"[[{note_name}]]", text, count=1)

        return text

    def _entity_file_path(self, entity_name: str) -> Path:
        """–ü—É—Ç—å –∫ .md —Ñ–∞–π–ª—É –¥–ª—è entity"""
        # –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª—ã –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ –≤ –∏–º–µ–Ω–∞—Ö —Ñ–∞–π–ª–æ–≤
        safe_name = re.sub(r'[<>:"/\\|?*]', '_', entity_name)
        return self.vault_path / f"{safe_name}.md"

    def _format_with_frontmatter(self, frontmatter: dict, body: str) -> str:
        """–°–æ–±–∏—Ä–∞–µ—Ç —Ñ–∞–π–ª: frontmatter + body"""
        fm_str = yaml.dump(frontmatter, allow_unicode=True, default_flow_style=False).strip()
        return f"---\n{fm_str}\n---\n\n{body.strip()}\n"

    def _parse_frontmatter(self, content: str) -> tuple[dict, str]:
        """–ü–∞—Ä—Å–∏—Ç frontmatter –∏–∑ —Ñ–∞–π–ª–∞"""
        match = re.match(r"^---\s*\n(.*?)\n---\s*\n", content, re.DOTALL)
        if not match:
            return {}, content
        try:
            fm = yaml.safe_load(match.group(1)) or {}
        except yaml.YAMLError:
            fm = {}
        body = content[match.end():]
        return fm, body

    def _extract_existing_facts(self, body: str) -> list[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–∫—Ç—ã –∏–∑ body"""
        facts = []
        for line in body.split("\n"):
            line = line.strip()
            if line.startswith("- "):
                # –£–±–∏—Ä–∞–µ–º [[links]] –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                clean = re.sub(r"\[\[([^\]]+)\]\]", r"\1", line[2:])
                facts.append(clean.lower().strip())
        return facts

    def _fact_exists(self, new_fact: str, existing_facts: list[str]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–æ–π —Ñ–∞–∫—Ç (–Ω–µ—á—ë—Ç–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ)"""
        new_clean = new_fact.lower().strip()
        for existing in existing_facts:
            # –ü—Ä–æ—Å—Ç–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ: –µ—Å–ª–∏ >70% —Å–ª–æ–≤ —Å–æ–≤–ø–∞–¥–∞—é—Ç
            new_words = set(new_clean.split())
            existing_words = set(existing.split())
            if not new_words:
                continue
            overlap = len(new_words & existing_words) / len(new_words)
            if overlap > 0.7:
                return True
        return False

    def get_vault_stats(self) -> dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ vault"""
        files = list(self.vault_path.glob("*.md"))
        types = {}
        for f in files:
            content = f.read_text(encoding="utf-8")
            fm, _ = self._parse_frontmatter(content)
            t = fm.get("type", "unknown")
            types[t] = types.get(t, 0) + 1
        return {"total_notes": len(files), "by_type": types}

    def list_notes(self) -> list[str]:
        """–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–º–µ—Ç–æ–∫"""
        return sorted([p.stem for p in self.vault_path.glob("*.md")])


if __name__ == "__main__":
    from engine.extractor.conversation_extractor import (
        ConversationExtractor, MockLLMClient
    )

    print("üß™ –¢–µ—Å—Ç Vault Manager\n")

    # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞–Ω–∏—è (mock)
    extractor = ConversationExtractor(MockLLMClient())
    conversation = [
        {"role": "user", "content": "–Ø —Ä–∞–±–æ—Ç–∞—é –≤ Uzum Bank, backend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫. –î–µ–ª–∞—é –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã –Ω–∞ Spring Boot."},
        {"role": "assistant", "content": "–ö–∞–∫–∏–µ –ë–î –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ?"},
        {"role": "user", "content": "PostgreSQL 15. –ü—Ä–æ–±–ª–µ–º–∞ —Å connection pool –≤ –ü—Ä–æ–µ–∫—Ç Alpha."},
    ]
    extraction = extractor.extract(conversation)

    # 2. –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ vault
    vault = VaultManager("./test_vault_auto")
    stats = vault.process_extraction(extraction)

    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç:")
    print(f"   –°–æ–∑–¥–∞–Ω–æ: {stats['created']}")
    print(f"   –û–±–Ω–æ–≤–ª–µ–Ω–æ: {stats['updated']}")

    # 3. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Å–æ–∑–¥–∞–ª–æ—Å—å
    print(f"\nüìÅ –§–∞–π–ª—ã –≤ vault:")
    for note in vault.list_notes():
        print(f"   üìÑ {note}.md")

    print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {vault.get_vault_stats()}")

    # 4. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    user_file = vault.vault_path / "User.md"
    if user_file.exists():
        print(f"\n{'='*50}")
        print(f"üìÑ User.md:")
        print(f"{'='*50}")
        print(user_file.read_text())
